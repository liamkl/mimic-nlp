{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('\\d+|\\d+\\.\\d+', '[NUM]', text)\n",
    "\n",
    "    # PHI tags are in format [**INFORMATION**]\n",
    "    text = re.sub('(\\[\\*\\*.*?\\*\\*\\])', '[PHI]', text)\n",
    "#     phi_tags = re.findall('(\\[\\*\\*.*?\\*\\*\\])', text)\n",
    "#     for i, tag in enumerate(phi_tags):\n",
    "#         text = text.replace(tag, '__PHI_{}__'.format(i))\n",
    "        \n",
    "    text = re.sub('---+', '\\n\\n-----\\n\\n', text)\n",
    "    text = re.sub('___+', '\\n\\n_____\\n\\n', text)\n",
    "    text = re.sub('[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
    "    text = re.sub('\\\\+', ' ', text)\n",
    "    text = re.sub('-|/', '_', text)\n",
    "    text = re.sub('_+', '_', text)\n",
    "    text = re.sub('\\*|\\(|\\)', ' ', text)\n",
    "    text = re.sub('['+'!\"#$%&\\'()*+,-./:;<=>?@\\\\^`{|}~'+']', '', text)\n",
    "    text = re.sub('\\s_\\s', ' ', text)\n",
    "    text = re.sub('\\r+|\\n+|\\u0085+|\\u2028+|\\u2029+', ' ', text) # Replace newlines\n",
    "    text = re.sub('\\s+|\\u00A0+', ' ', text) # Replace multiple spaces w/ single    \n",
    "    segments = text.split(' ')\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS = \"../data/NOTEEVENTS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "with open(NOTEEVENTS, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, note in enumerate(reader):\n",
    "        note = preprocess_text(note[-1])\n",
    "        notes.append(note)\n",
    "#         if note[6] == 'Discharge summary':\n",
    "#             note = preprocess_text(note[-1])\n",
    "#             notes.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.fasttext import FastText\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=300, window=10, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "model.train(lines, total_examples=len(lines), epochs=5)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model_gensim2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match(['cipro', 'dexamethasone', 'radiology', 'sitagliptin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_text.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string1(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    text = text.strip().lower().replace('-', '_').replace('.', '_').replace(' ', '_').rstrip('_')\n",
    "    return text\n",
    "\n",
    "def preprocess_text2(query):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    query = re.sub('\\d+|\\d+\\.\\d+', '[NUM]', query)\n",
    "    query = re.sub('(\\[\\*\\*.*?\\*\\*\\])', '[PHI]', query)\n",
    "    query = query.strip('\"').strip('?').strip(\"'\").strip('(').strip(')').strip(':')\n",
    "    query = re.sub('['+'!\"#$%&\\'()*+,-./:;<=>?@\\\\^`{|}~'+']', '', query)\n",
    "    word_list = query.split()\n",
    "    word_list = [clean_string1(word) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes2 = []\n",
    "with open(NOTEEVENTS, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, note in enumerate(reader):\n",
    "        note = preprocess_text2(note[-1])\n",
    "        notes2.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_text.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(notes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes2 = []\n",
    "with open(\"processed_text.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for note in reader:\n",
    "        notes2.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText(size=300, window=10, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "ft_model.build_vocab(notes2)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "ft_model.train(notes2, total_examples=len(notes2), epochs=5)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save('fasttext_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(size=300, window=10, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "w2v_model.build_vocab(notes2)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "w2v_model.train(notes2, total_examples=len(notes2), epochs=5)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('w2v_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing input data/fake labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/envs/py36/lib/python3.6/site-packages/ipykernel/__main__.py:3: DeprecationWarning: Call to deprecated `syn0` (Attribute will be removed in 4.0.0, use self.wv.vectors instead).\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "word_vectors = Word2Vec.load('w2v_embeddings')\n",
    "# word_vectors = FastText.load('fasttext_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = word_vectors.wv.vectors.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_notes = []\n",
    "with open(NOTEEVENTS, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, note in enumerate(reader):\n",
    "        if note[6] == 'Discharge summary':\n",
    "            note = preprocess_text2(note[-1])\n",
    "            input_notes.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# for local testing subset notes to 5000\n",
    "subset_notes = input_notes[:5000][:]\n",
    "\n",
    "N = len(subset_notes)\n",
    "# Create fake labels\n",
    "p = [0.4, 0.28, 0.22, 0.19, 0.16]\n",
    "y = np.array([[np.random.binomial(1, p[i]) for i in range(len(p))] for x in range(N)])\n",
    "# Create 70/30 train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(subset_notes, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 0\n",
    "for note in subset_notes:\n",
    "    if len(note) > MAXLEN:\n",
    "        MAXLEN = len(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "max_words = len(w2v_model.wv.vocab)\n",
    "max_words = 15000\n",
    "token = Tokenizer(max_words)\n",
    "token.fit_on_texts(subset_notes)\n",
    "vocab_size = max_words + 1\n",
    "\n",
    "sequences = token.texts_to_sequences(x_train)\n",
    "test_sequences = token.texts_to_sequences(x_test)\n",
    "## Convert to sequences ##\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "seq_len = 3000\n",
    "X = pad_sequences(sequences, maxlen=seq_len)\n",
    "X_test = pad_sequences(test_sequences, maxlen=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 46242 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "vocab = token.word_index.keys()\n",
    "for word in vocab:\n",
    "    if word in w2v_model.wv.vocab:\n",
    "      coefs = np.asarray(w2v_model.wv[word], dtype='float32')\n",
    "      embeddings_index[word] = coefs\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = token.word_index\n",
    "embedding_matrix = np.zeros((vocab_size , embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    if i < vocab_size:\n",
    "      embedding_vector = embeddings_index.get(word)\n",
    "      if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "          embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "3500/3500 [==============================] - 2450s 700ms/step - loss: 0.5789 - acc: 0.7272\n",
      "Epoch 2/25\n",
      "2944/3500 [========================>.....] - ETA: 6:12 - loss: 0.5616 - acc: 0.7425"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Input, Dropout, Bidirectional, GaussianNoise\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "\n",
    "## Build the model ##\n",
    "input = Input(shape=(seq_len,))\n",
    "x = Embedding(input_dim = vocab_size , output_dim = embedding_dim, weights=[embedding_matrix], trainable=False)(input)\n",
    "x = GaussianNoise(0.75)(x)\n",
    "x = Bidirectional(GRU(units = 128, recurrent_dropout=0.2, dropout=0.2, activation = 'relu', return_sequences=True))(x)\n",
    "x = Bidirectional(GRU(units = 128, recurrent_dropout=0.2, dropout=0.2, activation = 'relu'))(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(num_classes, activation='sigmoid')(x)\n",
    "model = Model(input,x)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X,y_train,epochs=25, batch_size = 128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
