{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    text = text.strip().lower()\n",
    "    text = re.sub('\\d+|\\d+\\.\\d+', '[NUM]', text)\n",
    "\n",
    "    # PHI tags are in format [**INFORMATION**]\n",
    "    text = re.sub('(\\[\\*\\*.*?\\*\\*\\])', '[PHI]', text)\n",
    "#     phi_tags = re.findall('(\\[\\*\\*.*?\\*\\*\\])', text)\n",
    "#     for i, tag in enumerate(phi_tags):\n",
    "#         text = text.replace(tag, '__PHI_{}__'.format(i))\n",
    "        \n",
    "    text = re.sub('---+', '\\n\\n-----\\n\\n', text)\n",
    "    text = re.sub('___+', '\\n\\n_____\\n\\n', text)\n",
    "    text = re.sub('[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
    "    text = re.sub('\\\\+', ' ', text)\n",
    "    text = re.sub('-|/', '_', text)\n",
    "    text = re.sub('_+', '_', text)\n",
    "    text = re.sub('\\*|\\(|\\)', ' ', text)\n",
    "    text = re.sub('['+'!\"#$%&\\'()*+,-./:;<=>?@\\\\^`{|}~'+']', '', text)\n",
    "    text = re.sub('\\s_\\s', ' ', text)\n",
    "    text = re.sub('\\r+|\\n+|\\u0085+|\\u2028+|\\u2029+', ' ', text) # Replace newlines\n",
    "    text = re.sub('\\s+|\\u00A0+', ' ', text) # Replace multiple spaces w/ single    \n",
    "    segments = text.split(' ')\n",
    "    \n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEEVENTS = \"../data/NOTEEVENTS.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = []\n",
    "with open(NOTEEVENTS, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, note in enumerate(reader):\n",
    "        note = preprocess_text(note[-1])\n",
    "        notes.append(note)\n",
    "#         if note[6] == 'Discharge summary':\n",
    "#             note = preprocess_text(note[-1])\n",
    "#             notes.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.fasttext import FastText\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText(size=300, window=10, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "\n",
    "model.train(lines, total_examples=len(lines), epochs=5)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('saved_model_gensim2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match(['cipro', 'dexamethasone', 'radiology', 'sitagliptin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_text.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_string1(text):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    text = text.strip().lower().replace('-', '_').replace('.', '_').replace(' ', '_').rstrip('_')\n",
    "    return text\n",
    "\n",
    "def preprocess_text2(query):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    query = re.sub('\\d+|\\d+\\.\\d+', '[NUM]', query)\n",
    "    query = re.sub('(\\[\\*\\*.*?\\*\\*\\])', '[PHI]', query)\n",
    "    query = query.strip('\"').strip('?').strip(\"'\").strip('(').strip(')').strip(':')\n",
    "    query = re.sub('['+'!\"#$%&\\'()*+,-./:;<=>?@\\\\^`{|}~'+']', '', query)\n",
    "    word_list = query.split()\n",
    "    word_list = [clean_string1(word) for word in word_list]\n",
    "    return word_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes2 = []\n",
    "with open(NOTEEVENTS, \"r\") as file:\n",
    "    reader = csv.reader(file)\n",
    "    for i, note in enumerate(reader):\n",
    "        note = preprocess_text2(note[-1])\n",
    "        notes2.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_text.csv\", \"w\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(notes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes2 = []\n",
    "with open(\"processed_text.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for note in reader:\n",
    "        notes2.append(note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes2[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models.fasttext import FastText\n",
    "from gensim.models import Word2Vec\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = FastText(size=300, window=10, min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "638.9453610269993\n",
      "FastText(vocab=208155, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "ft_model.build_vocab(notes2)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25857.242537287995\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "ft_model.train(notes2, total_examples=len(notes2), epochs=5)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model.save('fasttext_embeddings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(size=300, window=10, min_count=5, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355.62777747400105\n",
      "FastText(vocab=208155, size=300, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "w2v_model.build_vocab(notes2)\n",
    "\n",
    "end = timer()\n",
    "print(end-start)\n",
    "print(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15519.88943515101\n"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "\n",
    "w2v_model.train(notes2, total_examples=len(notes2), epochs=5)\n",
    "\n",
    "end = timer()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save('w2v_embeddings')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
